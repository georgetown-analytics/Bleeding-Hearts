{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "close-bailey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program run at 2021-06-23 16:13:20.385525\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import io, s3fs, json, traceback\n",
    "pd.set_option('display.max_columns', None)\n",
    "print('Program run at', dt.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "common-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings from scikit-learn to make this notebook a bit nicer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Models may be implemented as pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Used to divide our dataseets into train/test splits\n",
    "# Data will be randomly shuffled so running this notebook multiple times may lead to different results\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "# Visual analysis of model performance\n",
    "from yellowbrick.classifier import confusion_matrix\n",
    "from yellowbrick.classifier import classification_report\n",
    "from yellowbrick.regressor import prediction_error, ResidualsPlot\n",
    "\n",
    "# Set the default figure size for matplotlib\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "#Pipeline toolset\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import RobustScaler, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "\n",
    "#Model toolset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#Evaluation toolset\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.features import FeatureImportances\n",
    "from sklearn.metrics import accuracy_score\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "#from yellowbrick.datasets import load_game\n",
    "from yellowbrick.target import ClassBalance\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "characteristic-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removed features more than 80% corellated with each other\n",
    "est_rmv = pd.read_csv('s3://bleeding-hearts/workingdata/est_rmv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "composed-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_labels = ['Very Low', 'Low', 'Moderate', 'High', 'Very High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "enhanced-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = make_column_selector(dtype_include=np.object)\n",
    "numeric = make_column_selector(dtype_include=np.int64)\n",
    "numeric2 = make_column_selector(dtype_include=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = est_rmv.loc[:, est_rmv.columns != 'Child Opportunity Levels, overall COI, nationally-normed']\n",
    "y = est_rmv['Child Opportunity Levels, overall COI, nationally-normed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_rmv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hundred-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_cb(y,lst):\n",
    "    visualizer = ClassBalance(labels=lst)\n",
    "    visualizer.fit(y)        # Fit the data to the visualizer\n",
    "    visualizer.show()        # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "assigned-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balance(df,target):\n",
    "    print('Raw Value Counts:','\\n',df[target].value_counts())\n",
    "    X = df.loc[:, df.columns != target]\n",
    "    y = df[target]\n",
    "    #make a dataframe of value counts and a list of the values in the target\n",
    "    df1 = y.value_counts().to_frame('count').reset_index(level=0).rename(columns={'index':'value'})\n",
    "    label_lst = list(df1['value'])\n",
    "    \n",
    "    viz_cb(y,label_lst)\n",
    "\n",
    "    #identify minimum value number and label name\n",
    "    mi = df1['count'].min()\n",
    "    name = df1.loc[df1['count'] == mi,'value'].iloc[0]\n",
    "    print('min value is',name,'in values',label_lst)\n",
    "\n",
    "    seed = 123\n",
    "    # Downsample majority class\n",
    "    \n",
    "    #use min value number and label name to resample the dataframe\n",
    "    df2 = pd.concat([resample(df[df[target]== i],\n",
    "                            replace=False,\n",
    "                            n_samples=mi,\n",
    "                            random_state=seed) for i in label_lst if i != name]).append(df[df[target]== name])\n",
    "    print('Resampled Value Counts:','\\n',df2[target].value_counts())\n",
    "    X = df2.loc[:, df.columns != target]\n",
    "    y = df2[target]\n",
    "    viz_cb(y,label_lst)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "headed-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X,y):\n",
    "    X_train, X_test, y_train, y_test = tts(X, y, test_size=.2)\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "religious-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(X, y, estimator,**kwargs):\n",
    "    \"\"\"\n",
    "    Test various estimators.\n",
    "    \"\"\"\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    model = Pipeline([\n",
    "    (\"columns\", ColumnTransformer([\n",
    "        ('onehot', OneHotEncoder(), categorical),\n",
    "        ('scalar', RobustScaler(), numeric),\n",
    "        ('scalar2', RobustScaler(), numeric2),\n",
    "    ], remainder='drop')),\n",
    "        (\"imputer\",SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "    # Instantiate the classification model and visualizer\n",
    "    model.fit(X, y, **kwargs)\n",
    "    \n",
    "    expected  = y\n",
    "    predicted = model.predict(X)\n",
    "    \n",
    "\n",
    "    # Compute and return F1 (harmonic mean of precision and recall)\n",
    "    print(\"F1 SCORE {}: {}\".format(estimator.__class__.__name__, f1_score(expected, predicted,average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ranging-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(X, y, estimator,**kwargs):\n",
    "    \"\"\"\n",
    "    Test various estimators.\n",
    "    \"\"\"\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    model = Pipeline([\n",
    "    (\"columns\", ColumnTransformer([\n",
    "        ('onehot', OneHotEncoder(), categorical),\n",
    "        ('scalar', RobustScaler(), numeric),\n",
    "        ('scalar2', RobustScaler(), numeric2),\n",
    "    ], remainder='drop')),\n",
    "        (\"imputer\",SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)\n",
    "    # Instantiate the classification model and visualizer\n",
    "    visualizer = ClassificationReport(\n",
    "        model, classes=cat_labels,\n",
    "        cmap=\"YlGn\", size=(600, 360), **kwargs\n",
    "    )\n",
    "    visualizer.fit(X_train, y_train)\n",
    "    visualizer.score(X_test, y_test)\n",
    "    visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "industrial-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(X,y,estimator,**kwargs):\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    model = Pipeline([\n",
    "    (\"columns\", ColumnTransformer([\n",
    "        ('onehot', OneHotEncoder(), categorical),\n",
    "        ('scalar', RobustScaler(), numeric),\n",
    "        ('scalar2', RobustScaler(), numeric2),\n",
    "    ], remainder='drop')),\n",
    "        (\"imputer\",SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "\n",
    "    #Create the train and test data\n",
    "    X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)\n",
    "    #model.fit(X, y)\n",
    "    # Instantiate the visualizer with the classification model\n",
    "    confusion_matrix(\n",
    "        model,\n",
    "        X_train, y_train, X_test, y_test,\n",
    "        classes=cat_labels\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "contrary-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(X,y,estimator,**kwargs):\n",
    "        y = LabelEncoder().fit_transform(y)\n",
    "        model = Pipeline([\n",
    "    (\"columns\", ColumnTransformer([\n",
    "        ('onehot', OneHotEncoder(), categorical),\n",
    "        ('scalar', RobustScaler(), numeric),\n",
    "        ('scalar2', RobustScaler(), numeric2),\n",
    "    ], remainder='drop')),\n",
    "        (\"imputer\",SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "        #Create the train and test data\n",
    "        X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)\n",
    "    # Instantiate the visualizer with the classification model\n",
    "\n",
    "        visualizer = ROCAUC(model, classes=cat_labels)\n",
    "\n",
    "        visualizer.fit(X_train, y_train)        # Fit the training data to the visualizer\n",
    "        visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "        visualizer.show()                       # Finalize and show the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "instant-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_imp(X,y,estimator,**kwargs):\n",
    "        y = LabelEncoder().fit_transform(y)\n",
    "        model = Pipeline([\n",
    "    (\"columns\", ColumnTransformer([\n",
    "        ('onehot', OneHotEncoder(), categorical),\n",
    "        ('scalar', RobustScaler(), numeric),\n",
    "        ('scalar2', RobustScaler(), numeric2),\n",
    "    ], remainder='drop')),\n",
    "        (\"imputer\",SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "        #Create the train and test data\n",
    "        X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)\n",
    "    # Instantiate the visualizer with the classification model\n",
    "    \n",
    "        viz = model\n",
    "        viz.fit(X_train,y_train)\n",
    "        viz.fit(X_test,y_test)\n",
    "        viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-dispatch",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y = LabelEncoder().fit_transform(y)\n",
    "model = Pipeline([\n",
    "(\"columns\", ColumnTransformer([\n",
    "('onehot', OneHotEncoder(), categorical),\n",
    "('scalar', RobustScaler(), numeric),\n",
    "('scalar2', RobustScaler(), numeric2),\n",
    "], remainder='drop')),\n",
    "(\"imputer\",SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "('estimator', SVC(kernel='linear'))\n",
    "])\n",
    "#Create the train and test data\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)\n",
    "# Instantiate the visualizer with the classification model\n",
    "\n",
    "viz = FeatureImportances(model.named_steps['estimator'],size=(2000,2500))\n",
    "viz.fit(X_train,y_train)\n",
    "viz.fit(X_test,y_test)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    SVC(),BaggingClassifier(),AdaBoostClassifier(),GradientBoostingClassifier()] \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.named_steps['estimator'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-litigation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = class_balance(est_rmv,'Child Opportunity Levels, overall COI, nationally-normed')\n",
    "X = data.loc[:, data.columns != 'Child Opportunity Levels, overall COI, nationally-normed']\n",
    "y = data['Child Opportunity Levels, overall COI, nationally-normed']\n",
    "train_test(X,y)\n",
    "for model in models:\n",
    "    try:\n",
    "        score_model(X, y, model)\n",
    "        visualize_model(X, y, model)\n",
    "        conf_matrix(X, y, model)\n",
    "        roc_auc(X, y, model)\n",
    "    except Exception as exc:\n",
    "        print(model, \n",
    "              traceback.format_exc(), \n",
    "              exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-depth",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-score",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
