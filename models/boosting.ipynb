{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-franklin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "outdoor-revolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program run at 2021-06-15 10:23:41.217231\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import io, s3fs, json, traceback\n",
    "pd.set_option('display.max_columns', None)\n",
    "print('Program run at', dt.now())\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from pandas import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings from scikit-learn to make this notebook a bit nicer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Models may be implemented as pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Used to divide our dataseets into train/test splits\n",
    "# Data will be randomly shuffled so running this notebook multiple times may lead to different results\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "# Visual analysis of model performance\n",
    "from yellowbrick.classifier import confusion_matrix\n",
    "from yellowbrick.classifier import classification_report\n",
    "from yellowbrick.regressor import prediction_error, ResidualsPlot\n",
    "\n",
    "# Set the default figure size for matplotlib\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "#Pipeline toolset\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "\n",
    "#Model toolset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#Evaluation toolset\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.features import FeatureImportances\n",
    "\n",
    "#from yellowbrick.datasets import load_game\n",
    "from yellowbrick.target import ClassBalance\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "conventional-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('s3://bleeding-hearts/workingdata/est_rmv.csv')\n",
    "df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "X = df.loc[:, df.columns != 'Child Opportunity Levels, overall COI, nationally-normed']\n",
    "y = df['Child Opportunity Levels, overall COI, nationally-normed']\n",
    "cat_labels = list(set(df['Child Opportunity Levels, overall COI, nationally-normed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "english-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X,y):\n",
    "    X_train, X_test, y_train, y_test = tts(X, y, test_size=.2)\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "toxic-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = make_column_selector(dtype_include=np.object)\n",
    "numeric = make_column_selector(dtype_include=np.int64)\n",
    "numeric2 = make_column_selector(dtype_include=np.float64)\n",
    "\n",
    "\n",
    "models = [\n",
    "    Lasso(), Ridge(), ElasticNet(),SVC(gamma='auto'),\n",
    "    BaggingClassifier(), ExtraTreesClassifier(n_estimators=300),\n",
    "    RandomForestClassifier(n_estimators=300),GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "     max_depth=1, random_state=0), AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "]\n",
    "\n",
    "\n",
    "def score_model(X, y, estimator, **kwargs):\n",
    "    \"\"\"\n",
    "    Test various estimators.\n",
    "    \"\"\"\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    model = Pipeline([\n",
    "    (\"columns\", ColumnTransformer([\n",
    "        ('onehot', OneHotEncoder(), categorical),\n",
    "        ('scalar', RobustScaler(), numeric),\n",
    "        ('scalar2', RobustScaler(), numeric2),\n",
    "    ], remainder='drop')),\n",
    "        (\"imputer\",SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "    # Instantiate the classification model and visualizer\n",
    "    model.fit(X, y, **kwargs)\n",
    "\n",
    "    expected  = y\n",
    "    predicted = model.predict(X)\n",
    "    \n",
    "\n",
    "    # Compute and return F1 (harmonic mean of precision and recall)\n",
    "    print(\"F1 SCORE {}: {}\".format(estimator.__class__.__name__, f1_score(expected, predicted,average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "expected-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "\n",
    "\n",
    "def visualize_model(X, y, estimator,label_lst, **kwargs):\n",
    "    \"\"\"\n",
    "    Test various estimators.\n",
    "    \"\"\"\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    model = Pipeline([\n",
    "    (\"columns\", ColumnTransformer([\n",
    "        ('onehot', OneHotEncoder(), categorical),\n",
    "        ('scalar', RobustScaler(), numeric),\n",
    "        ('scalar2', RobustScaler(), numeric2),\n",
    "    ], remainder='drop')),\n",
    "        (\"imputer\",SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "    # Instantiate the classification model and visualizer\n",
    "    visualizer = ClassificationReport(\n",
    "        model, classes=label_lst,\n",
    "        cmap=\"YlGn\", size=(600, 360), support=True, **kwargs\n",
    "    )\n",
    "    visualizer.fit(X, y)\n",
    "    visualizer.score(X, y)\n",
    "    visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-carter",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14566, 63) (14566,)\n",
      "(3642, 63) (3642,)\n",
      "Lasso() Traceback (most recent call last):\n",
      "  File \"<ipython-input-24-816ebf10843f>\", line 4, in <module>\n",
      "    score_model(X, y, model)\n",
      "  File \"<ipython-input-22-e3de0472c58f>\", line 37, in score_model\n",
      "    print(\"F1 SCORE {}: {}\".format(estimator.__class__.__name__, f1_score(expected, predicted,average='micro')))\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1044, in f1_score\n",
      "    return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1168, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1433, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1250, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 90, in _check_targets\n",
      "    raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n",
      "ValueError: Classification metrics can't handle a mix of multiclass and continuous targets\n",
      " Classification metrics can't handle a mix of multiclass and continuous targets\n",
      "Ridge() Traceback (most recent call last):\n",
      "  File \"<ipython-input-24-816ebf10843f>\", line 4, in <module>\n",
      "    score_model(X, y, model)\n",
      "  File \"<ipython-input-22-e3de0472c58f>\", line 37, in score_model\n",
      "    print(\"F1 SCORE {}: {}\".format(estimator.__class__.__name__, f1_score(expected, predicted,average='micro')))\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1044, in f1_score\n",
      "    return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1168, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1433, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1250, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 90, in _check_targets\n",
      "    raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n",
      "ValueError: Classification metrics can't handle a mix of multiclass and continuous targets\n",
      " Classification metrics can't handle a mix of multiclass and continuous targets\n",
      "ElasticNet() Traceback (most recent call last):\n",
      "  File \"<ipython-input-24-816ebf10843f>\", line 4, in <module>\n",
      "    score_model(X, y, model)\n",
      "  File \"<ipython-input-22-e3de0472c58f>\", line 37, in score_model\n",
      "    print(\"F1 SCORE {}: {}\".format(estimator.__class__.__name__, f1_score(expected, predicted,average='micro')))\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1044, in f1_score\n",
      "    return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1168, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1433, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1250, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/Users/sarahmartin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 90, in _check_targets\n",
      "    raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n",
      "ValueError: Classification metrics can't handle a mix of multiclass and continuous targets\n",
      " Classification metrics can't handle a mix of multiclass and continuous targets\n"
     ]
    }
   ],
   "source": [
    "train_test(X,y)\n",
    "for model in models:\n",
    "    try:\n",
    "        score_model(X, y, model)\n",
    "        visualize_model(X, y, model,cat_labels)\n",
    "    except Exception as exc:\n",
    "        print(model, \n",
    "              traceback.format_exc(), \n",
    "              exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-impact",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-brush",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
