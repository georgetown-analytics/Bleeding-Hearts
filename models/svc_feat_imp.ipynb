{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "meaning-rainbow",
   "metadata": {},
   "source": [
    "# Step 4: Feature Correlation\n",
    "In this notebook, we assess the importance of different features using the American Community Survey (ACS) estimate data as features and the overall childhood opportunity index as the target. We identify 56 of 119 features that are more than 80% correlated and remove those features from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handed-trick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program run at 2021-06-24 17:34:17.947795\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import io, s3fs, json, traceback\n",
    "pd.set_option('display.max_columns', None)\n",
    "print('Program run at', dt.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "secret-hardware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18208 entries, 0 to 18207\n",
      "Columns: 120 entries, EMPLOYMENT STATUS_Population 16 years and over to Child Opportunity Levels, overall COI, nationally-normed\n",
      "dtypes: float64(118), int64(1), object(1)\n",
      "memory usage: 16.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#read in the estimate data with the overall COI as the target\n",
    "est = pd.read_csv('s3://bleeding-hearts/workingdata/est_rmv.csv')\n",
    "est.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "est.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stock-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings from scikit-learn to make this notebook a bit nicer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Models may be implemented as pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Used to divide our dataseets into train/test splits\n",
    "# Data will be randomly shuffled so running this notebook multiple times may lead to different results\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "# Visual analysis of model performance\n",
    "from yellowbrick.classifier import confusion_matrix\n",
    "from yellowbrick.classifier import classification_report\n",
    "from yellowbrick.regressor import prediction_error, ResidualsPlot\n",
    "\n",
    "# Set the default figure size for matplotlib\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "#Pipeline toolset\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "\n",
    "#Model toolset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#Evaluation toolset\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.features import FeatureImportances\n",
    "\n",
    "#from yellowbrick.datasets import load_game\n",
    "from yellowbrick.target import ClassBalance\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "super-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute mean values for missing values\n",
    "means = {}\n",
    "cols=list(est_rmv)\n",
    "for c in cols:\n",
    "    if len(est_rmv) - est_rmv[c].count() > 0:\n",
    "        means[c] = est_rmv[c].dropna().mean()\n",
    "est_rmv.fillna(value=means,inplace=True)\n",
    "#check that there are no more missing values\n",
    "est_rmv.columns[est_rmv.isnull().any()]\n",
    "#replace string classes with numbers\n",
    "num = {\n",
    "    'Very Low':1,\n",
    "    'Low':2,\n",
    "    'Moderate':3,\n",
    "    'High':4,\n",
    "    'Very High':5\n",
    "}\n",
    "cols=list(est_rmv.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "\n",
    "def f_importances(coef, names):\n",
    "    imp = coef\n",
    "    imp,names = zip(*sorted(zip(imp,names)))\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.show()\n",
    "\n",
    "svm = svm.SVC(kernel='linear')\n",
    "\n",
    "X = est_rmv.loc[:, est_rmv.columns != 'Child Opportunity Levels, overall COI, nationally-normed']\n",
    "y = est_rmv['Child Opportunity Levels, overall COI, nationally-normed']\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "f_importances(svm.coef_, cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
